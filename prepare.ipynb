{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realism 1000\n",
      "Rococo 1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "item_map = {\n",
    "    'Realism': [],\n",
    "    'Rococo': []\n",
    "}\n",
    "\n",
    "item_to_idx = {\n",
    "    'Realism': 0,\n",
    "    'Rococo': 0\n",
    "}\n",
    "\n",
    "data_dir = '/projects/data/wikiart/'\n",
    "counter = 0\n",
    "for category in item_map.keys():\n",
    "    fnames = os.listdir(data_dir + category)[0:1000]\n",
    "    \n",
    "    for fn in fnames:\n",
    "        item_map[category].append({\n",
    "            'idx': counter,\n",
    "            'label': item_to_idx[category],\n",
    "            'filename': category + '/' + fn,\n",
    "        })\n",
    "        counter += 1\n",
    "    \n",
    "for k in item_map:\n",
    "    print(k, len(item_map[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for category in item_map.keys():\n",
    "    random.shuffle(item_map[category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lst(image_arr, base_dir, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        count = 0\n",
    "        for img in image_arr:\n",
    "            label = img['label']\n",
    "            img_path = os.path.join(base_dir, img['filename'])\n",
    "            new_line = '\\t'.join([str(count), str(label), str(img_path)])\n",
    "            new_line += '\\n'\n",
    "            f.write(new_line)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "min_data_len = sys.maxsize\n",
    "\n",
    "for category in item_map.keys():\n",
    "    min(min_data_len, len(item_map[category]))\n",
    "\n",
    "sample = (0, 8)\n",
    "train = (0, int(min_data_len * 0.7))\n",
    "validation = (int(min_data_len * 0.7), int(min_data_len * 0.85))\n",
    "test = (int(min_data_len * 0.85), int(min_data_len * 1))\n",
    "\n",
    "def split_dataset(from_idx, to_idx):\n",
    "    result = []\n",
    "    for category in item_map.keys():\n",
    "        result = result + item_map[category][from_idx: to_idx]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample set is for developing model and debugging\n",
    "# because debugging with large dataset takes a long time\n",
    "sample_set = split_dataset(sample[0], sample[1])\n",
    "write_lst(sample_set, '/projects/data/wikiart/', '/projects/data/wikiart/sample.lst')\n",
    "\n",
    "train_set = split_dataset(train[0], train[1])\n",
    "write_lst(train_set, '/projects/data/wikiart/', '/projects/data/wikiart/train.lst')\n",
    "\n",
    "validation_set = split_dataset(validation[0], validation[1])\n",
    "write_lst(validation_set, '/projects/data/wikiart/', '/projects/data/wikiart/validation.lst')\n",
    "\n",
    "test_set = split_dataset(test[0], test[1])\n",
    "write_lst(validation_set, '/projects/data/wikiart/', '/projects/data/wikiart/test.lst')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNet(\n",
      "  (features): HybridSequential(\n",
      "    (0): Conv2D(3 -> 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "    (2): Activation(relu)\n",
      "    (3): Conv2D(1 -> 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "    (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)\n",
      "    (5): Activation(relu)\n",
      "    (6): Conv2D(32 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "    (8): Activation(relu)\n",
      "    (9): Conv2D(1 -> 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "    (10): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "    (11): Activation(relu)\n",
      "    (12): Conv2D(64 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (13): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "    (14): Activation(relu)\n",
      "    (15): Conv2D(1 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "    (16): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "    (17): Activation(relu)\n",
      "    (18): Conv2D(128 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (19): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "    (20): Activation(relu)\n",
      "    (21): Conv2D(1 -> 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "    (22): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "    (23): Activation(relu)\n",
      "    (24): Conv2D(128 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (25): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "    (26): Activation(relu)\n",
      "    (27): Conv2D(1 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "    (28): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "    (29): Activation(relu)\n",
      "    (30): Conv2D(256 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (31): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "    (32): Activation(relu)\n",
      "    (33): Conv2D(1 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "    (34): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "    (35): Activation(relu)\n",
      "    (36): Conv2D(256 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (37): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (38): Activation(relu)\n",
      "    (39): Conv2D(1 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "    (40): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (41): Activation(relu)\n",
      "    (42): Conv2D(512 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (43): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (44): Activation(relu)\n",
      "    (45): Conv2D(1 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "    (46): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (47): Activation(relu)\n",
      "    (48): Conv2D(512 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (49): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (50): Activation(relu)\n",
      "    (51): Conv2D(1 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "    (52): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (53): Activation(relu)\n",
      "    (54): Conv2D(512 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (55): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (56): Activation(relu)\n",
      "    (57): Conv2D(1 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "    (58): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (59): Activation(relu)\n",
      "    (60): Conv2D(512 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (61): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (62): Activation(relu)\n",
      "    (63): Conv2D(1 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "    (64): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (65): Activation(relu)\n",
      "    (66): Conv2D(512 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (67): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (68): Activation(relu)\n",
      "    (69): Conv2D(1 -> 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
      "    (70): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "    (71): Activation(relu)\n",
      "    (72): Conv2D(512 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (73): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "    (74): Activation(relu)\n",
      "    (75): Conv2D(1 -> 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
      "    (76): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "    (77): Activation(relu)\n",
      "    (78): Conv2D(1024 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (79): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "    (80): Activation(relu)\n",
      "    (81): GlobalAvgPool2D(size=(1, 1), stride=(1, 1), padding=(0, 0), ceil_mode=True)\n",
      "    (82): Flatten\n",
      "  )\n",
      "  (output): Dense(1024 -> 1000, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon.model_zoo.vision import mobilenet1_0\n",
    "pretrained_net = mobilenet1_0(pretrained=True)\n",
    "print(pretrained_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mobilenet1_0(classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "net.features = pretrained_net.features\n",
    "net.output.initialize(init.Xavier())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.image import color_normalize\n",
    "from mxnet import image\n",
    "train_augs = [\n",
    "    image.ResizeAug(224),\n",
    "    image.HorizontalFlipAug(0.5),  # flip the image horizontally\n",
    "    image.BrightnessJitterAug(.3), # randomly change the brightness\n",
    "    image.HueJitterAug(.1)         # randomly change hue\n",
    "]\n",
    "test_augs = [\n",
    "    image.ResizeAug(224)\n",
    "]\n",
    "def transform(data, label, augs):\n",
    "    data = data.astype('float32')\n",
    "    for aug in augs:\n",
    "        data = aug(data)\n",
    "    data = nd.transpose(data, (2,0,1))\n",
    "    return data, nd.array([label]).asscalar().astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.data.vision import ImageRecordDataset\n",
    "train_rec = '/projects/data/wikiart/train.rec' # train\n",
    "validation_rec = '/projects/data/wikiart/validation.rec'\n",
    "trainIterator = ImageRecordDataset(\n",
    "    filename=train_rec, \n",
    "    transform=lambda X, y: transform(X, y, train_augs)\n",
    ")\n",
    "\n",
    "validationIterator = ImageRecordDataset(\n",
    "    filename=validation_rec,\n",
    "    transform=lambda X, y: transform(X, y, test_augs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, ctx, \n",
    "          batch_size=64, epochs=10, learning_rate=0.01, wd=0.001):\n",
    "    train_data = gluon.data.DataLoader(\n",
    "        trainIterator, batch_size, shuffle=True)\n",
    "    validation_data = gluon.data.DataLoader(\n",
    "        validationIterator, batch_size)\n",
    "    net.collect_params().reset_ctx(ctx)\n",
    "    net.hybridize()\n",
    "    \n",
    "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {\n",
    "        'learning_rate': learning_rate, 'wd': wd})\n",
    "    \n",
    "    train_util(net, train_data, validation_data, \n",
    "               loss, trainer, ctx, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from mxnet.image import color_normalize\n",
    "from mxnet import autograd\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "import json\n",
    "\n",
    "def evaluate_accuracy(data_iterator, net):\n",
    "    acc = mx.metric.Accuracy()\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(ctx) # a big array\n",
    "        label = label.as_in_context(ctx) # \"accuracy\"\n",
    "        data = color_normalize(data/255,\n",
    "                               mean=mx.nd.array([0.485, 0.456, 0.406]).reshape((1,3,1,1)),\n",
    "                               std=mx.nd.array([0.229, 0.224, 0.225]).reshape((1,3,1,1)))\n",
    "        output = net(data) # an array\n",
    "        prediction = nd.argmax(output, axis=1) # an NDArray\n",
    "        acc.update(preds=prediction, labels=label)\n",
    "    \n",
    "    print(json.dumps(acc.get()))\n",
    "    \n",
    "    return acc.get()[1]\n",
    "\n",
    "def metric_str(names, accs):\n",
    "    return ', '.join(['%s=%f'%(name, acc) for name, acc in zip(names, accs)])\n",
    "\n",
    "def train_util(net, train_iter, validation_iter, loss_fn, trainer, ctx, epochs, batch_size):\n",
    "    metric = mx.metric.create(['acc'])\n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, label) in enumerate(train_iter):\n",
    "            st = time.time()\n",
    "            # ensure context            \n",
    "            data = data.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            # normalize images\n",
    "            data = color_normalize(data/255,\n",
    "                                   mean=mx.nd.array([0.485, 0.456, 0.406]).reshape((1,3,1,1)),\n",
    "                                   std=mx.nd.array([0.229, 0.224, 0.225]).reshape((1,3,1,1)))\n",
    "            \n",
    "            with autograd.record():\n",
    "                output = net(data)\n",
    "                loss = loss_fn(output, label)\n",
    "\n",
    "            loss.backward()\n",
    "            trainer.step(data.shape[0])\n",
    "            \n",
    "            #  Keep a moving average of the losses\n",
    "            metric.update([label], [output])\n",
    "            names, accs = metric.get()\n",
    "            print('[Epoch %d Batch %d] speed: %f samples/s, training: %s'%(epoch, i, batch_size/(time.time()-st), metric_str(names, accs)))\n",
    "            if i%100 == 0:\n",
    "                net.collect_params().save('./checkpoints/%d-%d.params'%(epoch, i))\n",
    "\n",
    "        train_acc = evaluate_accuracy(train_iter, net)\n",
    "        validation_acc = evaluate_accuracy(validation_iter, net)\n",
    "        print(\"Epoch %s | training_acc %s | val_acc %s \" % (epoch, train_acc, validation_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-07 07:20:35.888868\n",
      "[Epoch 0 Batch 0] speed: 15.328608 samples/s, training: accuracy=0.109375\n",
      "[Epoch 0 Batch 1] speed: 15.436512 samples/s, training: accuracy=0.445312\n",
      "[Epoch 0 Batch 2] speed: 15.397572 samples/s, training: accuracy=0.614583\n",
      "[Epoch 0 Batch 3] speed: 15.395245 samples/s, training: accuracy=0.710938\n",
      "[Epoch 0 Batch 4] speed: 15.403290 samples/s, training: accuracy=0.768750\n",
      "[Epoch 0 Batch 5] speed: 15.353210 samples/s, training: accuracy=0.807292\n",
      "[Epoch 0 Batch 6] speed: 15.380855 samples/s, training: accuracy=0.834821\n",
      "[Epoch 0 Batch 7] speed: 15.345632 samples/s, training: accuracy=0.855469\n",
      "[Epoch 0 Batch 8] speed: 15.303424 samples/s, training: accuracy=0.871528\n",
      "[Epoch 0 Batch 9] speed: 15.277411 samples/s, training: accuracy=0.884375\n",
      "[Epoch 0 Batch 10] speed: 15.243418 samples/s, training: accuracy=0.894886\n",
      "[Epoch 0 Batch 11] speed: 14.181223 samples/s, training: accuracy=0.903646\n",
      "[Epoch 0 Batch 12] speed: 15.337754 samples/s, training: accuracy=0.911058\n",
      "[Epoch 0 Batch 13] speed: 15.317619 samples/s, training: accuracy=0.917411\n",
      "[Epoch 0 Batch 14] speed: 15.353249 samples/s, training: accuracy=0.922917\n",
      "[Epoch 0 Batch 15] speed: 15.390831 samples/s, training: accuracy=0.927734\n",
      "[Epoch 0 Batch 16] speed: 15.323786 samples/s, training: accuracy=0.931985\n",
      "[Epoch 0 Batch 17] speed: 15.281541 samples/s, training: accuracy=0.935764\n",
      "[Epoch 0 Batch 18] speed: 15.229464 samples/s, training: accuracy=0.939145\n",
      "[Epoch 0 Batch 19] speed: 15.319876 samples/s, training: accuracy=0.942187\n",
      "[Epoch 0 Batch 20] speed: 15.347882 samples/s, training: accuracy=0.944940\n",
      "[Epoch 0 Batch 21] speed: 15.307628 samples/s, training: accuracy=0.947443\n",
      "[Epoch 0 Batch 22] speed: 15.330881 samples/s, training: accuracy=0.949728\n",
      "[Epoch 0 Batch 23] speed: 15.309329 samples/s, training: accuracy=0.951823\n",
      "[Epoch 0 Batch 24] speed: 15.367836 samples/s, training: accuracy=0.953750\n",
      "[Epoch 0 Batch 25] speed: 15.315120 samples/s, training: accuracy=0.955529\n",
      "[Epoch 0 Batch 26] speed: 15.322501 samples/s, training: accuracy=0.957176\n",
      "[Epoch 0 Batch 27] speed: 15.347953 samples/s, training: accuracy=0.958705\n",
      "[Epoch 0 Batch 28] speed: 15.350053 samples/s, training: accuracy=0.960129\n",
      "[Epoch 0 Batch 29] speed: 15.387411 samples/s, training: accuracy=0.961458\n",
      "[Epoch 0 Batch 30] speed: 15.415723 samples/s, training: accuracy=0.962702\n",
      "[Epoch 0 Batch 31] speed: 15.321275 samples/s, training: accuracy=0.963867\n",
      "[Epoch 0 Batch 32] speed: 15.289721 samples/s, training: accuracy=0.964962\n",
      "[Epoch 0 Batch 33] speed: 15.374651 samples/s, training: accuracy=0.965993\n",
      "[Epoch 0 Batch 34] speed: 15.377807 samples/s, training: accuracy=0.966964\n",
      "[Epoch 0 Batch 35] speed: 15.391437 samples/s, training: accuracy=0.967882\n",
      "[Epoch 0 Batch 36] speed: 15.370198 samples/s, training: accuracy=0.968750\n",
      "[Epoch 0 Batch 37] speed: 15.346641 samples/s, training: accuracy=0.969572\n",
      "[Epoch 0 Batch 38] speed: 15.232876 samples/s, training: accuracy=0.970353\n",
      "[Epoch 0 Batch 39] speed: 15.417006 samples/s, training: accuracy=0.971094\n",
      "[Epoch 0 Batch 40] speed: 15.363812 samples/s, training: accuracy=0.971799\n",
      "[Epoch 0 Batch 41] speed: 15.332134 samples/s, training: accuracy=0.972470\n",
      "[Epoch 0 Batch 42] speed: 15.395251 samples/s, training: accuracy=0.973110\n",
      "[Epoch 0 Batch 43] speed: 15.282655 samples/s, training: accuracy=0.973722\n",
      "[Epoch 0 Batch 44] speed: 15.324188 samples/s, training: accuracy=0.974306\n",
      "[Epoch 0 Batch 45] speed: 15.353655 samples/s, training: accuracy=0.974864\n",
      "[Epoch 0 Batch 46] speed: 15.374342 samples/s, training: accuracy=0.975399\n",
      "[Epoch 0 Batch 47] speed: 15.380256 samples/s, training: accuracy=0.975911\n",
      "[Epoch 0 Batch 48] speed: 15.356408 samples/s, training: accuracy=0.976403\n",
      "[Epoch 0 Batch 49] speed: 15.288577 samples/s, training: accuracy=0.976875\n",
      "[Epoch 0 Batch 50] speed: 15.404864 samples/s, training: accuracy=0.977328\n",
      "[Epoch 0 Batch 51] speed: 15.293862 samples/s, training: accuracy=0.977764\n",
      "[Epoch 0 Batch 52] speed: 15.361011 samples/s, training: accuracy=0.978184\n",
      "[Epoch 0 Batch 53] speed: 15.368101 samples/s, training: accuracy=0.978588\n",
      "[Epoch 0 Batch 54] speed: 15.381128 samples/s, training: accuracy=0.978977\n",
      "[Epoch 0 Batch 55] speed: 15.333232 samples/s, training: accuracy=0.979353\n",
      "[Epoch 0 Batch 56] speed: 15.347688 samples/s, training: accuracy=0.979715\n",
      "[Epoch 0 Batch 57] speed: 15.303636 samples/s, training: accuracy=0.980065\n",
      "[Epoch 0 Batch 58] speed: 15.372850 samples/s, training: accuracy=0.980403\n",
      "[Epoch 0 Batch 59] speed: 15.405959 samples/s, training: accuracy=0.980729\n",
      "[Epoch 0 Batch 60] speed: 15.266799 samples/s, training: accuracy=0.981045\n",
      "[Epoch 0 Batch 61] speed: 15.302779 samples/s, training: accuracy=0.981351\n",
      "[Epoch 0 Batch 62] speed: 15.302652 samples/s, training: accuracy=0.981647\n",
      "[Epoch 0 Batch 63] speed: 15.324021 samples/s, training: accuracy=0.981934\n",
      "[Epoch 0 Batch 64] speed: 15.346550 samples/s, training: accuracy=0.982212\n",
      "[Epoch 0 Batch 65] speed: 15.358833 samples/s, training: accuracy=0.982481\n",
      "[Epoch 0 Batch 66] speed: 15.334437 samples/s, training: accuracy=0.982743\n",
      "[Epoch 0 Batch 67] speed: 15.331528 samples/s, training: accuracy=0.982996\n",
      "[Epoch 0 Batch 68] speed: 15.316538 samples/s, training: accuracy=0.983243\n",
      "[Epoch 0 Batch 69] speed: 15.336712 samples/s, training: accuracy=0.983482\n",
      "[Epoch 0 Batch 70] speed: 15.330066 samples/s, training: accuracy=0.983715\n",
      "[Epoch 0 Batch 71] speed: 15.305166 samples/s, training: accuracy=0.983941\n",
      "[Epoch 0 Batch 72] speed: 15.358397 samples/s, training: accuracy=0.984161\n",
      "[Epoch 0 Batch 73] speed: 15.387444 samples/s, training: accuracy=0.984375\n",
      "[Epoch 0 Batch 74] speed: 15.377142 samples/s, training: accuracy=0.984583\n",
      "[Epoch 0 Batch 75] speed: 15.303679 samples/s, training: accuracy=0.984786\n",
      "[Epoch 0 Batch 76] speed: 15.307087 samples/s, training: accuracy=0.984984\n",
      "[Epoch 0 Batch 77] speed: 15.338182 samples/s, training: accuracy=0.985176\n",
      "[Epoch 0 Batch 78] speed: 15.392918 samples/s, training: accuracy=0.985364\n",
      "[Epoch 0 Batch 79] speed: 15.353460 samples/s, training: accuracy=0.985547\n",
      "[Epoch 0 Batch 80] speed: 15.321873 samples/s, training: accuracy=0.985725\n",
      "[Epoch 0 Batch 81] speed: 15.338952 samples/s, training: accuracy=0.985899\n",
      "[Epoch 0 Batch 82] speed: 15.318848 samples/s, training: accuracy=0.986069\n",
      "[Epoch 0 Batch 83] speed: 15.307265 samples/s, training: accuracy=0.986235\n",
      "[Epoch 0 Batch 84] speed: 15.351907 samples/s, training: accuracy=0.986397\n",
      "[Epoch 0 Batch 85] speed: 15.336634 samples/s, training: accuracy=0.986555\n",
      "[Epoch 0 Batch 86] speed: 15.350841 samples/s, training: accuracy=0.986710\n",
      "[Epoch 0 Batch 87] speed: 15.216896 samples/s, training: accuracy=0.986861\n",
      "[Epoch 0 Batch 88] speed: 15.396770 samples/s, training: accuracy=0.987008\n",
      "[Epoch 0 Batch 89] speed: 15.370856 samples/s, training: accuracy=0.987153\n",
      "[Epoch 0 Batch 90] speed: 15.267847 samples/s, training: accuracy=0.987294\n",
      "[Epoch 0 Batch 91] speed: 15.390715 samples/s, training: accuracy=0.987432\n",
      "[Epoch 0 Batch 92] speed: 15.377974 samples/s, training: accuracy=0.987567\n",
      "[Epoch 0 Batch 93] speed: 15.327923 samples/s, training: accuracy=0.987699\n",
      "[Epoch 0 Batch 94] speed: 15.317034 samples/s, training: accuracy=0.987829\n",
      "[Epoch 0 Batch 95] speed: 15.309075 samples/s, training: accuracy=0.987956\n",
      "[Epoch 0 Batch 96] speed: 15.267267 samples/s, training: accuracy=0.988080\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import datetime\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "ctx = mx.cpu()\n",
    "train(net, ctx, batch_size=64, epochs=5, learning_rate=0.003)\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-07 07:12:03.860191\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import datetime\n",
    "print(datetime.datetime.now())\n",
    "ctx2 = mx.gpu()\n",
    "train(net, ctx2, batch_size=64, epochs=5, learning_rate=0.003)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo - another set of timings with mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = gluon.data.DataLoader(testIterator, 64)\n",
    "test_acc = evaluate_accuracy(test_data_loader, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
